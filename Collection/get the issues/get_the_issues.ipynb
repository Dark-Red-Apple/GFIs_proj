{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Alma.Z, Dark_red_apple\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "df_contri_rep = pd.read_csv('contri_rep_half.csv',usecols=['url'])\n",
    "# pages = [1,2,3,4,5]\n",
    "username = 'dark-red-apple'\n",
    "\n",
    "# from https://github.com/user/settings/tokens\n",
    "token = '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'\n",
    "for ind in df_contri_rep.index:\n",
    "\n",
    "    page = 1\n",
    "    while(True):\n",
    "        # repos_url = \"https://api.github.com/repos/hakimel/reveal.js/issues?per_page=100&page=\"+str(page)        \n",
    "        repos_url = df_contri_rep['url'][ind]+\"/issues?q=per_page=100&page=\"+str(page)        \n",
    "        page += 1\n",
    "        gh_session = requests.Session()\n",
    "        gh_session.auth = (username, token)\n",
    "        \n",
    "        repos = json.loads(gh_session.get(repos_url).text)\n",
    "        # print(repos_url)\n",
    "        json_object = json.dumps(repos, indent = 4)\n",
    "        dict = json.loads(json_object)\n",
    "        df2 = json_normalize(dict)\n",
    "        # print(df2['pull_request.url'].tail())\n",
    "        # print(df2['pull_request.url'])\n",
    "        if(page == 1 and df2.shape[0]<50):\n",
    "            break\n",
    "        if(df2.shape[0] ==0):\n",
    "            break\n",
    "        if 'pull_request.url' in df2.columns:\n",
    "            df2[['url','repository_url','labels','created_at','id','number','pull_request.url']].to_csv('issues_all_coll.csv', mode='a', index=False, header=False)\n",
    "        else:\n",
    "            df2[['url','repository_url','labels','created_at','id','number']].to_csv('issues_all_coll.csv', mode='a', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099\n",
      "1043\n",
      "            total created_at\n",
      "created_at                  \n",
      "2005            1 2005-01-01\n",
      "2006            1 2006-01-01\n",
      "2007            2 2007-01-01\n",
      "2008            3 2008-01-01\n",
      "2009            8 2009-01-01\n",
      "2010           22 2010-01-01\n",
      "2011           55 2011-01-01\n",
      "2012          114 2012-01-01\n",
      "2013          201 2013-01-01\n",
      "2014          318 2014-01-01\n",
      "2015          462 2015-01-01\n",
      "2016          579 2016-01-01\n",
      "2017          683 2017-01-01\n",
      "2018          790 2018-01-01\n",
      "2019          867 2019-01-01\n",
      "2020          930 2020-01-01\n",
      "2021          970 2021-01-01\n",
      "2022          890 2022-01-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_contri_rep = pd.read_csv('contri_rep.csv',usecols=['url'])\n",
    "all_issues_fin = pd.read_csv('all_issues_fin.csv',usecols=['repository_url','created_at'])\n",
    "all_issues_fin['created_at'] = pd.to_datetime(all_issues_fin['created_at'])\n",
    "print(df_contri_rep[\"url\"].nunique())\n",
    "print(all_issues_fin[\"repository_url\"].nunique())\n",
    "all_issues_count = all_issues_fin.groupby(all_issues_fin['created_at'].dt.year).agg(total = pd.NamedAgg('repository_url',aggfunc=pd.Series.nunique))\n",
    "\n",
    "all_issues_count['created_at']= all_issues_count.index\n",
    "all_issues_count['created_at'] = pd.to_datetime(all_issues_count['created_at'], format='%Y')\n",
    "print(all_issues_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd_r= pd.read_csv(\"issues_all_coll.csv\")\n",
    "# print(pd_r[pd_r['repository_url']=='https://api.github.com/repos/getredash/redash'])\n",
    "# print(pd_r)\n",
    "# print(pd_r[pd_r['pull_request.url'].notnull()])\n",
    "# print(pd_r[pd_r['pull_request.url'].isnull()])\n",
    "# print(pd_r[pd_r['pull_request.url'].isna()])\n",
    "# print(pd_r[pd_r['id']==1180734149])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd_r[pd_r['pull_request.url'].isna()])\n",
    "print(pd_r[pd_r['pull_request.url'].notnull()])\n",
    "pd_fin = pd_r[pd_r['pull_request.url'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_fin.to_csv('all_issues_fin.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f52e72c7da3d38588779b7e0225782288049d1c57ba0ce139b57ffcecc10718"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
